{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ae2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8daf833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../../data/test_data.csv\")  # Load test dataset\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "def get_textblob_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    return pd.Series([polarity, subjectivity])\n",
    "\n",
    "df[['Polarity_TextBlob', 'Subjectivity_TextBlob']] = df['text'].apply(get_textblob_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c17627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert polarity to class\n",
    "def polarity_to_class(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59242864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize time for recording inference time\n",
    "start = time.time()\n",
    "\n",
    "df['TextBlob_Prediction'] = df['Polarity_TextBlob'].apply(polarity_to_class) # Apply TextBlob sentiment analysis\n",
    "\n",
    "end = time.time()\n",
    "inference_time = end - start\n",
    "\n",
    "# Save computation time to CSV\n",
    "time_df = pd.DataFrame({\"TextBlob_InferenceTime (s)\": [inference_time]})\n",
    "time_df.to_csv(\"computation_time_textblob.csv\", index=False)\n",
    "\n",
    "print(\"Inference time: \", inference_time, \"seconds\")\n",
    "print(\"Inference time is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc943b",
   "metadata": {},
   "source": [
    "Save result to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only desired columns\n",
    "result_df = df[[\"id\", \"text\", \"TextBlob_Sentiment\"]]\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv(\"textblob_sentiment_output.csv\", index=False)\n",
    "\n",
    "print(\"Sentiment analysis complete. Output saved to 'textblob_sentiment_output.csv'.\")\n",
    "\n",
    "print(\"Output length:\", len(result_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0dee9",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ce559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "df_vader = pd.read_csv(\"textblob_sentiment_output.csv\")\n",
    "\n",
    "y_true = df[\"Analysis\"] # True value\n",
    "y_pred = df_vader[\"TextBlob_Sentiment\"] # Predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bdac40",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c906542",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13124be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per-class Precision, Recall, F1-score\n",
    "report_df.drop(['accuracy', 'macro avg', 'weighted avg'], inplace=True)\n",
    "report_df[['precision', 'recall', 'f1-score']].plot.bar(figsize=(10,6))\n",
    "report_df[['precision', 'recall', 'f1-score']].to_csv(\"classification_report_textblob.csv\") # Save classification report to CSV\n",
    "\n",
    "plt.title(\"Per-Class Precision, Recall, F1-score\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Sentiment Class\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"classification_report_textblob.png\") # Save classification report plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ab4a2",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab68e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=report_df.index)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=report_df.index)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_textblob.png\") # Save confusion matrix plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550a6d4",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "rounded_acc = round(acc, 4) # Round accuracy to 4 decimal places\n",
    "print(\"Overall Accuracy:\", rounded_acc)\n",
    "\n",
    "accuracy_df = pd.DataFrame([{\"Metric\": \"Overall Accuracy\", \"Score\": rounded_acc}])\n",
    "accuracy_df.to_csv(\"overall_accuracy_textblob.csv\", index=False) # Save overall accuracy to CSV\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
